# Assignment 03
## 1
<!-- Show that AB=I implies BA=I for some square matrices A and B.  -->
$\textit{Proof.}$$$AB=I\implies (AB)A=A \implies A(BA)=A \implies BA=I.\tag*{□}$$

## 2
Assume $f,g \in V.$ Then $$ 
\int_0^1 [cf(t)]^2\ dt= c^2\int_0^1f^2(t)\ dt \lt \infty \implies cf(t) \in V.
$$Also,
$$
\begin{aligned}
\int_0^1 [f(t)+g(t)]^2\ dt&=
\int_0^1 f^2(t)\ dt+ \int_0^1 g^2(t) \ dt + 2 \int_0^1 f(t)g(t) \ dt \\&\leq
\int_0^1 f^2(t)\ dt+ \int_0^1 g^2(t) \ dt + 2\int_0^1 |f(t)g(t)| \ dt \\&\leq
\int_0^1 f^2(t)\ dt+ \int_0^1 g^2(t) \ dt + \int_0^1 f^2(t)+g^2(t) \ dt \\&\lt
\infty.
\end{aligned}$$Hence$$
f(t) + g(t) \in V.$$$V$ is a vector space.



## 3
###(a)
Linearly independent.

###(b)
Linearly dependent.
$$\vec{v_1}-3\vec{v_2}+2\vec{v_3}+\vec{v_4}=\vec{0}.$$


## 4
$$
\left\{
   \left[
      \begin{array}{c}
      1\\
      0\\
      -2\\
      1
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      -2\\
      3\\
      -3\\
      4
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      3\\
      -6\\
      1\\
      -3
      \end{array}
   \right]
\right\}
$$



## 5
### (a)
Yes. The set of all $2\times 2$ diagonal matrices is a subset of $\Bbb R^{2\times 2}$ closed under linear combination.

### (b)
No. $U_{2\times 2} + L_{2\times 2} = M_{2\times 2},$ which is no longer triangular.

###(c)
Yes. The set of all $2\times 2$ lower triangular matrices is a subset of $\Bbb R^{2\times 2}$ closed under linear combination.

###(d)
No. The sum of two such matrices is a matrix $B$ with $b_{12} = 2.$

###(e)
Yes. The set of all $2\times 2$ matrices $B$ with $b_{11} = 0$ is a subset of $\Bbb R^{2\times 2}$ closed under linear combination.

###(f)
Yes. The set of all symmetric $2\times 2$  matrices is a subset of $\Bbb R^{2\times 2}$ closed under linear combination.

###(g)
No. For example, $A = \left[
      \begin{array}{cc}
      1&1\\
      0&0
      \end{array}
   \right], B = \left[
      \begin{array}{cc}
      0&0\\
      1&2
      \end{array}
   \right]
$ are two singular matrices. But their sum $A + B = \left[
      \begin{array}{cc}
      1&1\\
      1&2
      \end{array}
   \right]$ is non-singular.

## 6
### (a)
$$
\left[
   \begin{array}{c}
      18/5\\
      4/5\\
      7/5
   \end{array}
\right]
$$
###(b)
$$
x_3 \left[
   \begin{array}{c}
      2\\
      -1\\
      1\\
      0
   \end{array}
\right]+
x_4 \left[
   \begin{array}{c}
      -5\\
      1\\
      0\\
      1
   \end{array}
\right]+
\left[
   \begin{array}{c}
      -5\\
      1\\
      0\\
      0
   \end{array}
\right], \ (x_3, x_4) \in \Bbb R^2.
$$

## 7
###(a)
$$
\left[
   \begin{array}{ccc}
   1 & 2 & -3 \\
   -2 & -2 & 3 \\
   2 & 4 & 6
   \end{array}
\right]
\xrightarrow{E_{12}E_{13}E_{23}E_{31}E_{21}}
\left[
   \begin{array}{ccc}
   1 & 0 & 0 \\
   0 & 2 & 0 \\
   0 & 0 & 12
   \end{array}
\right].
$$Three column vectors are linearly independent. Hence
$$\dim(\cdot) = 3.$$


###(b)
Let $$\alpha (x^2-4) + \beta x^2(x^4-2)+ \theta(x^6-8) = 0.$$ Simplifying the equation, we obtain$$(\beta + \theta)x^6 + (\alpha -2\beta)x^2-4(\alpha+2\theta)=0$$which yields$$\alpha=2\beta=-2\theta.$$ This shows that$$
x^2(x^4-2)\in \text{span}(x^2-4,x^6-8).
$$Hence $\{x^2-4, x^6-8\}$ is a basis for the original span.
$$\dim{(\cdot)}=2.$$



## 8
###(a)
$\textit{Proof. }$ Let $S = \{\vec{x_1},...,\vec{x_n} \}$ be any set of $n$ linearly independent vectors in $V$. We need to prove that every vector in $V$ is in the span of vectors in S, by contradiction.
Suppose $\exists \vec v \in V \text{ s.t. } \vec v\notin \text{span}(\vec{x_1},...,\vec{x_n}),$ then $\vec v, \vec{x_1},...,\vec{x_n}$ are $(n+1)$ L.I. vectors in $V.$ We now use induction to show  this is impossible to happen with $\dim(V)=n,$ since any $(n+1)$ vectors in $n$-dimensional vector space $V$ must be L.D.
$\textbf{Base case. }$ If $n = 1,$ a basis for $V$ contains exactly one vector $\vec{b_1}.$ Suppose $\vec{v_1} = c_1\vec{b_1} $ and $\vec{v_2} = c_2\vec{b_1}$ are two non-zero vectors in $V$ (otherwise they are already L.D.). Clearly we may write $\vec{v_1}/c_1-\vec{v_2}/c_2=0,$ showing $\vec{v_1}, \vec{v_2}$ as L.D.
$\textbf{Inductive step. }$ Suppose in any $(n-1)$-dimensional vector space $V$, any $n$ vectors are L.D. We want to show this implies that in any $n$-dimensional $V$, any $(n+1)$ vectors $\vec{v_1},...,\vec{v_{n+1}}$ are L.D.
Let $B=\{\vec{b_1},...,\vec{b_n}\}$ be a basis for $V$. Then we may write
$$
\vec{v_1} = a_{11}\vec{b_1} + a_{12}\vec{b_2}+...+a_{1n}\vec{b_n}\tag{1}$$$$
\vec{v_2} = a_{21}\vec{b_1} + a_{22}\vec{b_2}+...+a_{2n}\vec{b_n}
\tag{2}$$$$ ⋮
$$$$
\vec{v_n} = a_{n1}\vec{b_1} + a_{n2}\vec{b_2}+...+a_{nn}\vec{b_n}\tag{n}$$$$
\vec{v}_{n+1} = a_{n+1,1}\vec{b_1} + a_{n+1,2}\vec{b_2}+...+a_{n+1,n}\vec{b_n}\tag{n+1}
$$Note that if $a_{11},a_{21},...a_{n+1,1}$ are all $0,$ then $\vec{v_1},...,\vec{v}_{n+1}$ are L.D. by the hypothesis. Hence we may assume, WLOG, that $a_{11}\neq 0.$ Multiply $\text{(1)}$ by $\frac{a_{i1}}{a_{11}}$ and obtain
$$
\frac{a_{i1}\vec{v_1}}{a_{11}} = a_{i1}\vec{b_1} + L_i(\vec{b_2},\vec{b_3},...,\vec{b_n}) \tag{1*}$$where $L_i(\cdot)$ is some linear combination of $\vec{b_2},\vec{b_3},...,\vec{b_n}.$ Now subtract $\text{(1*)}$ from equations $\text{(2), ..., (n+1)}$:
$$
\vec{v}_2^*:= \vec{v_2}-\frac{a_{21}\vec{v_1}}{a_{11}} = L^*_2(\vec{b_2},\vec{b_3},...,\vec{b_n}) \tag{2*}
$$$$⋮
$$$$
\vec{v}_n^*:=\vec{v_n}-\frac{a_{n1}\vec{v_1}}{a_{11}} = L^*_n(\vec{b_2},\vec{b_3},...,\vec{b_n}) \tag{n*}
$$$$
\vec{v}_{n+1}^*:=\vec{v}_{n+1}-\frac{a_{n+1,1}\vec{v_1}}{a_{11}} = L^*_{n+1}(\vec{b_2},\vec{b_3},...,\vec{b_n}) \tag{n+1*}
$$Note that $\vec{v}_2^*,...,\vec{v}_n^*,\vec{v}_{n+1}^*$ are $n$ vectors in $(n-1)$-dimensional vector space. By the hypothesis, they are L.D. i.e. $\exists $ non-trivial $\{\lambda_2,...,\lambda_n, \lambda_{n+1}\} \text{ s.t. }$ 
$$\lambda_2\vec{v}_2^*+...+\lambda_n\vec{v}_n^*+\lambda_{n+1}\vec{v}_{n+1}^*=\vec0.
$$Equivalently
$$
\lambda_2(\vec{v_2}-\frac{a_{21}\vec{v_1}}{a_{11}})+...+\lambda_n(\vec{v_n}-\frac{a_{n1}\vec{v_1}}{a_{11}})+\lambda_{n+1}(\vec{v}_{n+1}-\frac{a_{n+1,1}\vec{v_1}}{a_{11}})=\vec0.
$$Rearranging, we obtain
$$
-(\frac{\lambda_2 a_{21}}{a_{11}} +...+ \frac{\lambda_n a_{n1}}{a_{11}} + \frac{\lambda_{n+1} a_{n+1,1}}{a_{11}})\vec{v_1}+\lambda_2\vec{v_2}+...+\lambda_n\vec{v_n}+\lambda_{n+1}\vec{v}_{n+1} = \vec0.
$$showing $\vec{v_1},...,\vec{v}_{n+1}$ as L.D. This completes the induction and our proof.$$\tag*{□}$$
###(b)
$\textit{Proof. }$ Suppose $V = \text{span}(\vec {x_1},...,\vec{x_n}).$ We want to show $S = \{\vec {x_1},..., \vec {x_n}\}$ are L.I. Then by **(a)** $S$ forms a basis for $V$.
We shall prove by contradiction. Assume $S$ is L.D. Further assume, WLOG, that $S'=\{\vec{x_1},..., \vec{x_j}\}$ is a maximal L.I. subset of $S$. Then $V$ can be spanned solely by $S'$. But by **(a)** this creates a basis for $V$ with only $j$ vectors, implying $\dim (V) = j \neq n,$ the desired contradiction.$$\tag*{□}$$
##9
$$
\forall \vec x \in V, \vec x = 
\left[
   \begin{array}{c}
x_1\\
x_2\\
x_3\\
x_4
\end{array}
\right] = x_1\left[
   \begin{array}{c}
1\\
0\\
0\\
-1
\end{array}
\right]
+x_2\left[
   \begin{array}{c}
0\\
1\\
0\\
-1
\end{array}
\right]+x_3
\left[
   \begin{array}{c}
0\\
0\\
1\\
-1
\end{array}
\right].
$$Hence $$V=\text{span}(\left[
   \begin{array}{c}
1\\
0\\
0\\
-1
\end{array}
\right],\left[
   \begin{array}{c}
0\\
1\\
0\\
-1
\end{array}
\right],\left[
   \begin{array}{c}
0\\
0\\
1\\
-1
\end{array}
\right]). \tag{⁎}
$$The linear independence of $S$ together with $\text{(⁎)}$ implies that $S$ is a basis for $V.$ Moreover,
$$
\dim(V)=|S|=3.
$$ 
##10
###(a)
From $B,$ we observe the pivot variables at the first, second, and fifth columns. Hence a basis for $\text{Col}(A) $ $$S = \{a_1, a_2, a_5\} =\left\{
   \left[
      \begin{array}{c}
      1\\
      2\\
      1
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      2\\
      1\\
      1\\
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      0\\
      7\\
      2\\
      \end{array}
   \right]
\right\}$$and$$
\text{rank}(A) = |S| = 3. 
$$

###(b)
First note that $$
\text{N}(A) = \text{N}(B).
$$Solving $B x=0,$
$$
x = \left[
   \begin{array}{c}
-x_3-x_4+14x_6-14x_7\\
-x_3-2x_4-8x_6+5x_7\\
x_3\\
x_4\\
-4x_6+2x_7\\
x_6\\
x_7
\end{array}
\right]=
x_3\left[
   \begin{array}{c}
-1\\
-1\\
1\\
0\\
0\\
0\\
0
\end{array}
\right]+
x_4\left[
   \begin{array}{c}
-1\\
-2\\
0\\
1\\
0\\
0\\
0
\end{array}
\right]+
x_6\left[
   \begin{array}{c}
14\\
-8\\
0\\
0\\
-4\\
1\\
0
\end{array}
\right]+
x_7\left[
   \begin{array}{c}
-14\\
5\\
0\\
0\\
2\\
0\\
1
\end{array}
\right].
$$A basis for $\text N(B),$ therefore also a basis for $\text N(A),$ is then$$
S = \left\{
   \left[
      \begin{array}{c}
     -1\\
-1\\
1\\
0\\
0\\
0\\
0
      \end{array}
   \right],
   \left[
      \begin{array}{c}
-1\\
-2\\
0\\
1\\
0\\
0\\
0
      \end{array}
   \right],
   \left[
      \begin{array}{c}
14\\
-8\\
0\\
0\\
-4\\
1\\
0
      \end{array}
   \right],
   \left[
   \begin{array}{c}
-14\\
5\\
0\\
0\\
2\\
0\\
1
\end{array}
\right]
\right\}.
$$Moreover,
$$
\dim[\text N (A)] = |S| = 4.
$$
## 11
Let $$
\alpha y_1 + \beta y_2 +\theta y_3 = 0.$$Equivalently$$
\alpha(x_1+x_2)+\beta(x_2+x_3)+\theta(x_3+x_1) = 0.$$Rearranging,$$
(\alpha+\theta)x_1 + (\alpha+\beta)x_2 + (\beta+\theta)x_3 = 0.
$$From L.I. of $\{x_i\}$ it follows that$$
\alpha + \theta = \alpha + \beta =\beta + \theta = 0,
$$which implies $$\alpha = \beta = \theta = 0.$$Hence $\{y_i\}$ is also L.I.

## 12
###(1)
$q=3.$
###(2)
All $q \neq 3$ will do.
###(3)
Impossible; $\text{rank}(A) \leq 2.$


##13
$\textit{Proof. }$ Denote $\text{rank}(A)=r\leq m,$ which is the dimension of the row space of $A.$ WLOG assume (through row permutation) $\{\vec{a_1}, \vec{a_2}, ... \vec{a_r}\}$ is a maximal L.I. subset of $\{\vec{a_i}\},$ where $\vec{a_i}$ denotes the $i$-th row of $A.$ Note that $AB = [\vec{a_i} B].$ Then since $B$ is invertible, $\{\vec{a_1}B, \vec{a_2}B, ... \vec{a_r}B\}$ remains a maximal L.I. subset of $\{\vec{(ab)}_i\},$ where $\vec{(ab)}_i$ denotes the $i$-th row of $AB.$ Hence the dimension of the row space of $AB$ remains to be $r, $ i.e. $$\text{rank}(AB)=\text{rank}(A).\tag*{□}$$

##14
$\textit{Proof. }$ Denote $\text{rank}(A)$ as $\alpha,$ $\text{rank}(B)$ as $\beta,$ the $i$-th row of a matrix $M$ as $\vec{m_i}.$ WLOG assume $\{\vec{a_i}\}_{i=1}^\alpha$ is a maximal L.I. subset of $\{\vec{a_i}\}_{i=1}^m.$ Consider $\vec{a_1}.$ Since $AB=O,$$$
\vec{a_1}B = [a_{11}\ a_{12}\ ...\ a_{1n}]
\left[\begin{array}{c}
\vec{b_1}\\
\vec{b_2}\\
 ⋮\\
\vec{b_n}
\end{array}\right]=
\vec{0}, \tag{1}
$$with at least one entry in $\vec{a_1}$ being non-zero. WLOG assume $a_{1n} \neq 0,$ we may rewrite $\text{(1)}$ as$$
\vec{b_n} = -\frac1{a_{1n}}(a_{11}\vec{b_1}+a_{12}\vec{b_2}+...+a_{1,n-1}\vec{b}_{n-1}).
$$Hence$$
\vec{b_n} \in \text{span}(\vec{b_1},...,\vec b_{n-1})\implies \text{Row}(B)=\text{span}(\vec{b_1},...,\vec b_{n-1}).\tag{1*}
$$It follows that
$$\beta \leq |\{\vec{b_i}\}_{i=1}^{n-1}|=n-1.$$Similarly, consider $\vec{a_2},$
$$
\vec{a_2}B = [a_{21}\ a_{22}\ ...\ a_{2n}]
\left[\begin{array}{c}
\vec{b_1}\\
\vec{b_2}\\
 ⋮\\
\vec{b_n}
\end{array}\right]=
\vec{0}.
$$Combined with $\text{(1)}$ a little rearrangement yields
$$
(a_{1n}a_{21}-a_{2n}a_{11})\vec{b_1}+...+(a_{1n}a_{2,n-2}-a_{2n}a_{1,n-2})\vec{b}_{n-2}+(a_{1n}a_{2,n-1}-a_{2n}a_{1,n-1})\vec{b}_{n-1} = \vec 0 \tag{2}
$$From L.I. of $\{\vec{a_i}\}_{i=1}^\alpha,$ the coefficients $(a_{1n}a_{2i}-a_{2n}a_{1i})_{i=1}^{n-1}$ cannot all be zero. It follows that $\exists \vec{b_u} \in \{\vec{b_i}\}_{i=1}^{n-1}$ that we may take out without affecting the row space, thus$$\beta \leq (n-1)-1=n-2.$$Continuing the same process for every row in $\{\vec{a_i}\}_{i=1}^\alpha$. Each time $\vec{a_i}B = \vec{0}$ and the L.I. of $\{\vec{a_i}\}_{i=1}^\alpha$ together implies a new redundant row in $\{\vec{b_i}\}_{i=1}^n$ for spanning $\text{Row}(B)$, reducing the upper bound for $\beta$ by $1.$ We obtain at last$$
\beta \leq n-|\{\vec{a_i}\}_{i=1}^\alpha|=n-\alpha.\tag*{□}
$$



##15
$\textit{Proof. }$ If $x \in \text{N}(A),$ then $$ A^TAx=A^T(Ax)=A0=0 \implies x \in \text{N}(A^TA).$$If $x \in \text{N}(A^TA),$ then
$$
A^TAx=0 \implies x^TA^TAx=0 \iff
(Ax)^TAx=0 \implies
Ax=0 \implies x\in \text{N}(A).
$$Therefore $$\text{N}(A)=\text{N}(A^TA).\tag*{□}$$


## 16
$\textit{Proof. }$ Denote $\text{rank}(A)$ as $\alpha,$ $\text{rank}(B)$ as $\beta, i$-th column of a matrix $M$ as $m_i.$ WLOG assume $\{a_i\}_{i=1}^\alpha$ is a maximal L.I. subset of $\{a_i\},$$\ \{b_i\}_{i=1}^\beta$ a maximal L.I. subset of $\{b_i\}.$ Then $\{a_i\}_{i=1}^\alpha$ spans $\text{Col}(A);\ \{b_i\}_{i=1}^\beta$ spans $\text{Col}(B).$ Consequently$ \ \{a_i\}_{i=1}^\alpha \cup \{b_i\}_{i=1}^\beta$ spans $\text{Col}(A+B),$ and$$
\text{rank}(A+B)\leq |\{a_i\}_{i=1}^\alpha \cup \{b_i\}_{i=1}^\beta| = \alpha + \beta.\tag*{□}
$$


##17
###(1)
$$T(A+B)=(A+B)+(A+B)^T=A+A^T+B+B^T=T(A)+T(B)$$$$
T(cA)=cA+(cA)^T=c(A+A^T)=c\ T(A).
$$
###(2)
Let $$T(A)=A+A^T=O.$$$$
\left[
\begin{array}{cc}
2a_{11}& a_{12}+a_{21}\\
a_{21}+a_{12}& 2a_{22}
\end{array}
\right]=\left[
\begin{array}{cc}
0& 0\\
0& 0
\end{array}
\right]\implies
A=\left[
\begin{array}{cc}
0& a_{12}\\
-a_{12}& 0
\end{array}
\right].
$$Therefore$$
\ker(T)=
\left\{
   A\ | \ A=\left[
\begin{array}{cc}
0& x\\
-x& 0
\end{array}
\right]
\right\}.
$$

##18
$\textit{Proof. }$ Suppose $L$ is one-to-one. Then
$$L(v_1)=L(v_2)\implies v_1=v_2$$$$\Downarrow$$$$
L(v_1)-L(v_2)=L(v_1-v_2)=0\implies v_1-v_2=0$$$$\Downarrow
$$$$\ker(L)={0}.$$Suppose $\ker(L)={0}.$ Then$$
L(v)=0\implies v=0
$$$$\Downarrow$$$$
L(v_1)-L(v_2)=L(v_1-v_2)=0\implies v_1-v_2=0
$$$$\Downarrow$$$$
L(v_1)=L(v_2)\implies v_1=v_2.
$$$L$ is one-to-one. Hence$$
L \text{ is one-to-one}\iff \ker(L)={0}.
\tag*{□}$$

##19
$$
L: \Bbb R^3{\rightarrow}\Bbb R^2.$$This transformation is determined by$$
B = \left\{
   \left[
      \begin{array}{c}
      1\\
      2\\
      1
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      2\\
      1\\
      1\\
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      0\\
      7\\
      2\\
      \end{array}
   \right]
\right\}\xrightarrow{L}\left\{
   \left[
      \begin{array}{c}
      2\\
      1
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      2\\
      3
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      -1\\
      2
      \end{array}
   \right]
\right\}\xrightarrow{\text{Rep}_{B'}}\left\{
   \left[
      \begin{array}{c}
      -2\\
      1
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      -2\\
      3
      \end{array}
   \right],
   \left[
      \begin{array}{c}
      1\\
      2
      \end{array}
   \right]
\right\}_{B'}.
$$Hence $$
\text{Rep}_{B,B'}(L)=\left[
   \begin{array}{ccc}
   -2 & -2 & 1 \\
   1 & 3 & 2 \\
   \end{array}
\right]_{B,B'}.
$$To find the $L(\vec u)$ and $\text{Rep}_{B'}[L(\vec u)]$, first use the fact that$$
\text{Rep}_{B}(\vec u)=   \left[
      \begin{array}{c}
      2\\
      1\\
      -1
      \end{array}
   \right]_B.
$$Then$$
\begin{aligned}
\text{Rep}_{B'}[L(\vec u)]&=\text{Rep}_{B,B'}(L)\text{Rep}_{B}(\vec u)\\&=
   \left[
   \begin{array}{ccc}
   -2 & -2 & 1 \\
   1 & 3 & 2 \\
   \end{array}
\right]\left[
      \begin{array}{c}
      2\\
      1\\
      -1
      \end{array}
   \right]_B\\&=
\left[
      \begin{array}{c}
      -7\\
      3
      \end{array}
   \right]_{B'}
\end{aligned}
$$Converting back,$$
L(\vec u)=[\vec{u}_1'\ |\ \vec{u}_2']\left[
      \begin{array}{c}
      -7\\
      3
      \end{array}
   \right]_{B'}=\left[
      \begin{array}{c}
      7\\
      3
      \end{array}
   \right].
$$
##20
```julia
julia> using LinearAlgebra

julia> # pairwise inner products are zero

julia> a1'a2
0.0

julia> a1'a3
0.0

julia> a2'a3
0.0

julia> # expansion of x in basis {a1, a2, a3}

julia> norm((a1'x)a1 + (a2'x)a2 + (a3'x)a3 - x)
4.577566798522237e-16
```

##21
```julia
julia> using LinearAlgebra
```
###(1)
```julia
julia> rank(A * B) <= min(rank(A), rank(B))
true
```
###(2)
```julia
julia> rank(A + B) <= rank(A) + rank(B)
true
```

##22
###(i)
@import "1.png"
###(ii)
@import "2.png"

##23
```julia
julia> X = count(x -> (rand() < p), 1:N)
4
```

##24
```julia
julia> total = 1e5;

julia> est_PI = 4 * hit / total
3.13388
```

@import "hi.png"