# STA2002 Assignment 3

*Chen Ang (118010009)*

## 1

### (a)

$$
\bar x =26,s^2=27.14
$$



### (b)

$$
H_0:\mu =\mu_0=26\\
H_1:\mu\gt\mu_0=26\\
T = \frac{\bar X -\mu_0}{\sigma/\sqrt n},\alpha=0.05
$$

### (c)

$$
t=\frac{\bar x -\mu_0}{\sigma/\sqrt n}=\frac{26-26}{4/\sqrt{15}}=0
$$

### (d)

Under null hypothesis,
$$
T\sim N(0,1)
$$
And so the p-value
$$
p=P(T\ge t=0)=0.5\gt0.05
$$
So Charles does not reject $H_0$ at $0.05$ significance level.

### (e)

We need
$$
\begin{aligned}
p&=P(T\ge t)\le 0.05
\end{aligned}
$$
which means
$$
t=\frac{\bar x -\mu_0}{\sigma/\sqrt n}\ge z_{0.05}
$$
Equivalently
$$
\begin{aligned}
\bar x&\ge\mu_0+z_{0.05}\sigma/\sqrt n\\
&=26+1.645\cdot 4/\sqrt{15}
\\&=27.70
\end{aligned}
$$
So $\bar x$ should at least be $27.7$ for Charles to reject $H_0.$

### (f)

The test statistics becomes
$$
T=\frac{\bar X -\mu_0}{S/\sqrt n}
$$
with realization
$$
t =\frac{\bar x -\mu_0}{s/\sqrt n}=0
$$
Under $H_0,$
$$
T\sim t(n-1)
$$
The p-value is given by
$$
p=P(T\ge t=0)=0.5\gt0.05
$$
Charles does not reject $H_0$ at $0.05$ significance level.

## 2

Denote the outcome of each coin flip by $X_1,\cdots X_{n=50} \overset{\text{i.i.d.}} \sim\text{Bernoulli}(p).$ 

The hypotheses:
$$
H_0: p=p_0=0.5\\
H_1:p\neq p_0=0.5
$$

### (a)

Since $n$ is relatively large, by CLT
$$
\hat p =\bar X = \frac{\sum_{i=1}^n X_i}n\overset{\text{approx}}\sim N\left(p, \frac{p(1-p)}n\right)
$$
We construct the statistic
$$
T=\frac{\hat p-p_0}{\sqrt{p_0(1-p_0)/n}}
$$
which has realization
$$
t=\frac{30/50-0.5}{\sqrt{0.5(1-0.5)/50}}= 1.414
$$
Under $H_0,$
$$
T\overset{\text{approx}}\sim N(0,1)
$$
We compute the p-value
$$
p=P(|T|\ge 1.414)=2\cdot P(Z\ge1.414)=0.157\gt0.05
$$
Hence Michael fails to reject $H_0.$

### (b)

Keeping $n=50$ and $\alpha=0.05,$ we want the p-value
$$
p=P(|T|\ge t)=2\cdot P(Z\ge t)\le \alpha
$$
which means
$$
P(Z\ge t)\le\frac\alpha2\iff t=\frac{h/n-p_0}{\sqrt{p_0(1-p_0)/n}}\ge z_{\alpha/2}
$$

Equivalently
$$
h\ge n\cdot\left(p_0+z_{\alpha/2}{\sqrt{p_0(1-p_0)/n}}\right)=31.9
$$
So $h$ at least needs to be $\lceil31.9\rceil=32$ for Michael to reject $H_0$ at $\alpha=0.05.$

## 3

### (a)

Given $\mu=\mu',$ 
$$
\bar X\sim N\left(\mu',\frac{\sigma^2} n\right)
$$
We falsely accept $H_0$ when the statistic $\bar x\not\in C,$ i.e.
$$
\bar x \le \mu_0+z_{\alpha}\frac\sigma{\sqrt n}
$$
with probability
$$
\begin{aligned}
P\left(\bar X \le \mu_0+z_{\alpha}\frac\sigma{\sqrt n}\right)&=P\left(\frac{\bar X-\mu'}{\sigma/\sqrt n}\le z_\alpha+\frac{\mu_0-\mu'}{\sigma/\sqrt n}\right)\\&
=P\left(Z\le z_\alpha+\frac{\mu_0-\mu'}{\sigma/\sqrt n}\right)
\\&=\beta(\mu')
\end{aligned}
$$
which is to be shown.
### (b)

We want
$$
\beta(\mu')=\Phi\left(z_\alpha+\frac{\mu_0-\mu'}{\sigma/\sqrt n}\right)=\beta
$$
Taking the inverse of $\Phi$ on both sides,
$$
z_\alpha+\frac{\mu_0-\mu'}{\sigma/\sqrt n}=\Phi^{-1}(\beta)=z_{1-\beta}=-z_\beta
$$
which yields
$$
n=\left(\frac{\sigma\left(z_{\alpha}+z_{\beta}\right)}{\mu_{0}-\mu^{\prime}}\right)^{2}\tag1
$$
as desired.

### (c)

Plugging $\alpha=0.025,\beta=0.05,\mu'=25000,\mu_0=24000,\sigma=1300$ into $(1),$ we need
$$
n=\left(\frac{1300\left(z_{0.025}+z_{0.05}\right)}{24000-25000}\right)^{2}=21.96\approx 22
$$
samples.

## 4

Sample size $n=12.$

### (a)

A $100(1-\alpha)\%$ C.I. for $\mu$ is given by
$$
\begin{aligned}
\bar x\pm z_{\alpha/2}(\sigma/\sqrt n)&=41.83\pm z_{\alpha/2}(11/\sqrt {12})\\
&=41.83\pm z_{\alpha/2}\cdot3.175
\end{aligned}
$$
To obtain a $90\%$ C.I., we set $\alpha=0.1,$ $z_{\alpha/2}=1.645,$ which gives
$$
41.83\pm5.22
$$

### (b)

Set $\alpha=0.05,z_{\alpha/2}=1.96.$ Thus a $95\%$ C.I. for $\mu$ is given by
$$
41.83\pm6.22
$$
Set instead $\alpha=0.01,z_{\alpha/2}=2.576.$ This yields a $99\%$ C.I. for $\mu:$
$$
41.83\pm 8.18
$$

### (c)

Without the knowledge of $\sigma^2,$ we estimate it by $S^2$ and reach a $100(1-\alpha)\%$ C.I.:
$$
\begin{aligned}

\bar x\pm t_{\alpha/2}(n-1)(s/\sqrt n)&= 41.83\pm t_{\alpha/2}(11)(11.8/\sqrt{12})
\\&=41.83\pm t_{\alpha/2}(11)\cdot 3.406

\end{aligned}
$$
Set $\alpha=0.1,t_{\alpha/2}(11)=1.796.$ The $100(1-\alpha)\%$ C.I. is given by
$$
41.83\pm6.12
$$

## 5

### (a)

Consider
$$
U:=\sum_{i=1}^n\left(\frac{X_i-\mu}\sigma\right)^2=\sum_{i=1}^nZ_i^2=\sum_{i=1}^nC_i
$$
where $Z_i\overset{\text{i.i.d}}{\sim}N(0,1),C_i\overset{\text{i.i.d}}{\sim}\chi^2(1).$ 

Due to additivity of i.i.d. Chi-square RVs,
$$
U\sim \chi^2(n)
$$
Hence
$$
\begin{aligned}

1-\alpha&=P\left(\chi^2_{1-\alpha/2}(n) \le U\le \chi^2_{\alpha/2}(n)\right)\\&=
P\left(\chi^2_{1-\alpha/2}(n) \le \sum_{i=1}^n\left(\frac{X_i-\mu}\sigma\right)^2\le \chi^2_{\alpha/2}(n)\right)\\&=
P\left(\chi^2_{1-\alpha/2}(n) \le \frac1{\sigma^2}\sum_{i=1}^n{(X_i-\mu)^2}\le \chi^2_{\alpha/2}(n)\right) \\&=
P\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{\alpha / 2}^{2}(n)} \le \sigma^2\le  \frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{1-\alpha / 2}^{2}(n)}\right)

\end{aligned}
$$

### (b)

Consider
$$
W:=\sum_{i=1}^{n}\left(\frac{X_{i}-\bar{X}}{\sigma}\right)^{2}=\frac{(n-1) S^{2}}{\sigma^{2}}\sim\chi^2(n-1)
$$

Similarly
$$
\begin{aligned}

1-\alpha&=P\left(\chi^2_{1-\alpha/2}(n-1) \le W\le \chi^2_{\alpha/2}(n-1)\right)\\&=
P\left(\chi^2_{1-\alpha/2}(n-1) \le \sum_{i=1}^n\left(\frac{X_i-\bar X}\sigma\right)^2\le \chi^2_{\alpha/2}(n-1)\right)\\&=
P\left(\chi^2_{1-\alpha/2}(n-1) \le \frac1{\sigma^2}\sum_{i=1}^n{(X_i-\bar X)^2}\le \chi^2_{\alpha/2}(n-1)\right) \\&=
P\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\bar X\right)^{2}}{\chi_{\alpha / 2}^{2}(n-1)} \le \sigma^2\le  \frac{\sum_{i=1}^{n}\left(X_{i}-\bar X\right)^{2}}{\chi_{1-\alpha / 2}^{2}(n-1)}\right)

\end{aligned}
$$

### (c)

By (b),
$$
\begin{aligned}

1-\alpha&=
P\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{\alpha / 2}^{2}(n-1)} \le \sigma^2\le  \frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{1-\alpha / 2}^{2}(n-1)}\right)\\
&=P\left(\sqrt{\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{\alpha / 2}^{2}(n-1)}} \le \sigma\le  \sqrt{\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}}{\chi_{1-\alpha / 2}^{2}(n-1)}}\right)

\end{aligned}
$$

## 6

Let
$$
f(\alpha,\beta):=\sum_{i=1}^nw_i(y_i-\alpha-\beta x_i)^2
$$
FONC:
$$
\begin{aligned}
\nabla_{\alpha}f(\alpha,\beta)&= \sum_{i=1}^n 2w_i(y_i-\alpha-\beta x_i)(-1)=0\\
\nabla_{\beta}f(\alpha,\beta)&= \sum_{i=1}^n 2w_i(y_i-\alpha-\beta x_i)(-x_i)=0\\
\end{aligned}
$$
Hence
$$
\begin{aligned}

\sum_{i} w_i(y_i-\alpha-\beta x_i)&=\sum_{i}w_iy_i-\alpha\sum_iw_i-\beta\sum_iw_ix_i=0\\
\sum_{i} w_ix_i(y_i-\alpha-\beta x_i)&=\sum_i w_iy_ix_i-\alpha\sum_i w_ix_i-\beta \sum_i w_ix_i^2=0\\

\end{aligned}
$$
Denote $A:=\sum_{i}w_iy_i,B:=\sum_{i}w_i,C:=\sum_{i}w_ix_i,D:=\sum_i w_iy_ix_i,E:=\sum_i w_ix_i^2.$ We then have
$$
A-B\alpha-C\beta=0\\
D-C\alpha-E\beta=0
$$
which yields
$$
\begin{aligned}
\alpha&=\alpha^*=\frac AB-\frac CB\beta\\
\beta&=\beta^*=\frac{BD-AC}{BE-C^2},
\end{aligned}
$$
the suggested answer. To validate optimality we further calculate the Hessian at $(\alpha^*,\beta^*)$
$$
H(\alpha^*,\beta^*)=2\left[\begin{array}{cc}
B& C\\
C& E
\end{array}\right]
$$
with eigenvalues $\lambda_1,\lambda_2$ satisfying
$$
\begin{aligned}
(\lambda_1+\lambda_2)/2&=B+E\gt0\\
\lambda_1\lambda_2/4&=BE-C^2\\
&=\sum_i w_i\sum_j w_jx_j^2-\left(\sum_kw_kx_k\right)^2\\
&=\sum_{i\neq j} {w_iw_jx_i(x_i-x_j)}\\
&=\sum_{i<j}w_iw_j(x_i-x_j)^2\gt0
\end{aligned}\implies \lambda_1,\lambda_2\gt0\implies H\succ0
$$
Hence by SOSC, $(\alpha^*,\beta^*)$ is the unique minimizer.

## 7

### (a)

$$
\bar x=3055.91,\bar y=3317.91
$$

### (b)

A $100(1-\alpha)\%$ C.I. for $\mu_X-\mu_Y$ is
$$
\bar{X}-\bar{Y} \pm t_{\alpha / 2}(n+m-2) S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}
$$
where
$$
S_{p}^{2}=\frac{(n-1) S_{X}^{2}+(m-1) S_{Y}^{2}}{n+m-2}
$$
is the pooled estimator of $\sigma^2.$

Since $n+m$ is large, we may use the approximation
$$
\bar{X}-\bar{Y} \pm z_{\alpha / 2} S_{p} \sqrt{\frac{1}{n}+\frac{1}{m}}
$$
With $\alpha=0.05,$ plug in
$$
n=13391,m=5672\\
\bar X =\bar x=3055.91, \bar Y = \bar y=3317.91\\
z_{\alpha/2}=1.96,S_p=1985.65
$$
we have the pooled t-interval
$$
-262.00\pm61.66
$$

### (c)

A $100(1-\alpha)\%$ Welch's t-interval for $\mu_X-\mu_Y$ is
$$
\bar{X}-\bar{Y} \pm t_{\alpha / 2}(r) \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
$$
where
$$
r=\left\lfloor\frac{\left(\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}\right)^{2}}{\frac{1}{n-1}\left(\frac{S_{X}^{2}}{n}\right)^{2}+\frac{1}{m-1}\left(\frac{S_{Y}^{2}}{m}\right)^{2}}\right\rfloor
$$
Since $n,m$ are both large, $r$ is also large. Hence we may use the approximation
$$
\bar{X}-\bar{Y} \pm z_{\alpha / 2} \sqrt{\frac{S_{X}^{2}}{n}+\frac{S_{Y}^{2}}{m}}
$$
Plugging in the data, we obtain
$$
-262.00\pm61.60
$$

### (d)

No. Instead, the data shows at 95% confidence level that there are *more* cars when the weather is "Rain".

-----



### Python Code

```python
import csv
import os, sys
import matplotlib.pyplot as plt
import numpy as np

class Traffic:
    def __init__(self, file=None):
        self.xs = []    # traffic when clear
        self.n = 0
        self.x_mean = None
        self.x_S2 = None

        self.ys = []    # traffic when rain
        self.m = 0
        self.y_mean = None
        self.y_S2 = None

        self.Sp2 = None
        self.pooled_max_err = None
        self.welch_max_err = None

        if file:
            self.load_data(file)

    def load_data(self, file):
        self.__init__()
        with open(file, newline='') as f:
            reader = csv.reader(f)
            data = list(reader)[1::]
            self.xs = [float(d[-1]) for d in data if d[5] == 'Clear']
            self.ys = [float(d[-1]) for d in data if d[5] == 'Rain']
            self.n, self.m = len(self.xs), len(self.ys)
            self.x_mean = sum(self.xs) / self.n
            self.y_mean = sum(self.ys) / self.m
            self.x_S2 = sum((x - self.x_mean) ** 2 for x in self.xs) / (self.n - 1)
            self.y_S2 = sum((y - self.y_mean) ** 2 for y in self.ys) / (self.m - 1)
            num = (self.n - 1) * self.x_S2 + (self.m - 1) * self.y_S2
            den = self.n + self.m - 2
            self.Sp2 = num / den
            self.pooled_max_err = 1.96 * self.Sp2 ** .5 * (1 / self.n + 1 / self.m) ** .5
            self.welch_max_err = 1.96 * (self.x_S2 / self.n + self.y_S2 / self.m) ** .5

    def plot(self):
        plt.scatter(self.xs, self.ys)
        if (self.a and self.b):
            X = np.arange(min(self.xs), max(self.xs), 0.01)
            Y = self.a + self.b * (X - self.x_mean)
            plt.plot(X, Y, 'r')
        plt.show()

    def print_stat(self):
        print("{:-^60}".format(" statistics"))
        print("{:<13}{:<13}{:<13}".format("", "x (clear)", "y (rain)"))
        print("{:<13}{:<13}{:<13}".format("size", self.n, self.m))
        print("{:<13}{:<13.2f}{:<13.2f}".format("mean", self.x_mean, self.y_mean))
        print("{:<13}{:<13.2f}{:<13.2f}".format("sample var", self.x_S2, self.y_S2))
        print("{:<13}{:<13.2f}({:<.2f})".format("Sp2 (Sp)", self.Sp2, self.Sp2 ** .5))
        print("{:<13}{:<13.2f}".format("pooled error", self.pooled_max_err))
        print("{:<13}{:<13.2f}\n".format("welch error", self.welch_max_err))

traffic = Traffic(os.path.join(sys.path[0], 'traffic.csv'))
traffic.print_stat()
```

### Output

```python
------------------------ statistics-------------------------
             x (clear)    y (rain)     
size         13391        5672         
mean         3055.91      3317.91      
sample var   3948572.02   3929230.64   
Sp2 (Sp)     3942817.60   (1985.65)
pooled error 61.66        
welch error  61.60        
```

